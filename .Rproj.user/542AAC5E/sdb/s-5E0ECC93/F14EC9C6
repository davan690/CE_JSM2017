{
    "collab_server" : "",
    "contents" : "### -----------------------------\n### Hui Lin\n### @gossip_rabbit\n### \n### http://scientistcafe.com\n### -----------------------------\n\n## Data Wrangling\n## -----------------------------\n# Should have loaded it \n# library(readr)\n\n## Read and write data: readr package\n\nread_csv(\"2015,2016,2017\n         1,2,3\n         4,5,6\")\n\nsim.dat <- read_csv(\"https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv \")\nhead(sim.dat)\n\ndat=read_csv(\"2015,2016,2017\n100,200,300\ncanola,soybean,corn\")\n\nprint(dat)\n\n## Baby example 2\n\ndat=read_csv(\"# I will never let you know that\n          # my favorite food is carrot\n             Date,Food,Mood\n             Monday,carrot,happy\n             Tuesday,carrot,happy\n             Wednesday,carrot,happy\n             Thursday,carrot,happy\n             Friday,carrot,happy\n             Saturday,carrot,extremely happy\n             Sunday,carrot,extremely happy\", skip = 2)\nprint(dat)\n\n## Baby example 3\n\ndat=read_csv(\"Saturday,carrot,extremely happy\n          Sunday,carrot,extremely happy\", col_names=FALSE)\nprint(dat)\n\n## `read_csv2()`\n\n# Read semicolon separated files\ndat=read_csv2(\"Saturday; carrot; extremely happy \\n Sunday; carrot; extremely happy\", col_names=FALSE)\nprint(dat)\n\n# Read tab delimited files\ndat=read_tsv(\"every\\tman\\tis\\ta\\tpoet\\twhen\\the\\tis\\tin\\tlove\\n\", col_names = FALSE)\nprint(dat)\n\n# Assign separating character\ndat=read_delim(\"THE|UNBEARABLE|RANDOMNESS|OF|LIFE\\n\", delim = \"|\", col_names = FALSE)\nprint(dat)\n\n# Substitute for missing value\n\ndat=read_csv(\"Q1,Q2,Q3\n               5,4,99\",na=\"99\")\nprint(dat)\n\n## data.table\n\n# library(data.table)\n# covert the existing data frame to data table\ndt <- data.table(sim.dat)\nclass(dt)\n\n# Calculate mean for counts of online transactions:\ndt[, mean(online_trans)]\n\n# Calculate mean by group:\ndt[ , mean(online_trans), by = gender]\n\n# group by more than one variables:\ndt[ , mean(online_trans), by = .(gender, house)]\n\n# Assign column names for aggregated variables:\ndt[ , .(avg = mean(online_trans)), by = .(gender, house)]\n\n# select row\n# select rows with age<20 and income > 80000\ndt[age < 20 & income > 80000]\n# select the first two rows\ndt[1:2]\n\n# select column\n# select column “age” but return it as a vector\n# the argument for row is empty so the result will return all observations\nans <- dt[, age]\nhead(ans)\n# To return `data.table` object, put column names in `list()`\n# Select age and online_exp columns and return as a data.table instead\nans <- dt[, list(age, online_exp)]\nhead(ans)\n# you can also put column names in `.()`\nans <- dt[, .(age, online_exp)]\n# head(ans)\n# To select all columns from “age” to “income”\nans <- dt[, age:income, with = FALSE]\nhead(ans,2)\n# Delete columns using `-` or `!`\n# delete columns from  age to online_exp\nans <- dt[, -(age:online_exp), with = FALSE]\nans <- dt[, !(age:online_exp), with = FALSE]\n\n# tabulation\n# row count\ndt[, .N]\n\n# Count by groups:\n# counts by gender\ndt[, .N, by= gender]  \n# for those younger than 30, count by gender\ndt[age < 30, .(count=.N), by= gender] \n\n\n# Order table:\n# get records with the highest 5 online expense:\nhead(dt[order(-online_exp)],5) \n# Since data table keep some characters of data frame, they share some operations\ndt[order(-online_exp)][1:5]\n# order the table by more than one variable\ndt[order(gender, -online_exp)][1:5]\n\n# `apply()`, `lapply()` and `sapply()` in base R\n## simulate a matrix\nx <- cbind(x1 =1:8, x2 = c(4:1, 2:5))\ndimnames(x)[[1]] <- letters[1:8]\napply(x, 2, mean)\ncol.sums <- apply(x, 2, sum)\nrow.sums <- apply(x, 1, sum)\n\n# apply other functions:\nma <- matrix(c(1:4, 1, 6:8), nrow = 2)\nma\napply(ma, 1, table)  #--> a list of length 2\napply(ma, 1, stats::quantile) # 5 x n matrix with rownames\n\n# Tricky example\n## Example with different lengths for each call\nz <- array(1:24, dim = 2:4)\nzseq <- apply(z, 1:2, function(x) seq_len(max(x)))\nzseq         ## a 2 x 3 matrix\ntypeof(zseq) ## list\ndim(zseq) ## 2 3\nzseq[1,]\napply(z, 3, function(x) seq_len(max(x)))\n\n# Read data\nsim.dat<-read.csv(\"https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv\")\n# Get numerical variables\nsdat<-sim.dat[,!lapply(sim.dat,class)==\"factor\"]\n## Try the following code with apply() function\n## apply(sim.dat,class)\n## Why is there the error?\napply(sdat, MARGIN=2,function(x) mean(na.omit(x)))\napply(sdat, MARGIN=2,function(x) sd(na.omit(x)))\nlapply(sdat, function(x) sd(na.omit(x)))\nsapply(sdat, function(x) sd(na.omit(x)))\nsapply(sdat, function(x) sd(na.omit(x)), simplify = FALSE)\n\n# dplyr - display\n\ntbl_df(sim.dat)\nglimpse(sim.dat)\n\n# dplyr - subset\nfilter(sim.dat, income >300000) %>%\n  tbl_df()\n\n# Pipe operator\n\n# piping with .\n\"Hello World\" %>% substring(7, 11) %>% grepl(\"Wo\", .)\n\n# without pipe\nave_exp <- filter( \n  summarise(\n    group_by( \n      filter(\n        sim.dat, \n        !is.na(income)\n      ), \n      segment\n    ), \n    ave_online_exp = mean(online_exp), \n    n = n()\n  ), \n  n > 200\n) \n\n# with pipe\navg_exp <- sim.dat %>% \n  filter(!is.na(income)) %>% \n  group_by(segment) %>% \n  summarise( \n    ave_online_exp = mean(online_exp), \n    n = n() ) %>% \n  filter(n > 200)\n\n# Subset - select rows\ndplyr::distinct(sim.dat)\n\n# random sample rows\ndplyr::sample_frac(sim.dat, 0.5, replace = TRUE) \ndplyr::sample_n(sim.dat, 10, replace = TRUE) \n\n# select rows by position\n# It is equivalent to `sim.dat[10:15,]`\ndplyr::slice(sim.dat, 10:15) \n\n# select the order top n entries\ndplyr::top_n(sim.dat,2,income)\n\n# Subset - select columns\n\n# select by column name\ndplyr::select(sim.dat,income,age,store_exp)\n\n# select columns whose name contains a character string\ndplyr::select(sim.dat, contains(\"_\"))\n\n# select columns whose name ends with a character string\n# similar there is \"starts_with\"\ndplyr::select(sim.dat, ends_with(\"e\"))\n\n# select columns Q1,Q2,Q3,Q4 and Q5\nselect(sim.dat, num_range(\"Q\", 1:5)) \n\n# select columns whose names are in a group of names\ndplyr::select(sim.dat, one_of(c(\"age\", \"income\")))\n\n# select columns between age and online_exp\ndplyr::select(sim.dat, age:online_exp)\n\n# select all columns except for age\ndplyr::select(sim.dat, -age)\n\n# Summarize\n\ndplyr::summarise(sim.dat, avg_online = mean(online_trans)) \n# apply function anyNA() to each column\n# you can also assign a function vector such as: c(\"anyNA\",\"is.factor\")\ndplyr::summarise_each(sim.dat, funs_(c(\"anyNA\")))\n\nsim.dat %>% group_by(segment) %>% summarise_each(funs_(c(\"anyNA\")))\n\n# Create new variable\n\n# `mutate()`: compute and append one or more new columns:\ndplyr::mutate(sim.dat, total_exp = store_exp + online_exp)\n\n# min_rank=rank(ties.method = \"min\")\n# mutate_each() means apply function to each column\ndplyr::mutate_each(sim.dat, funs(min_rank)) \n\n# `transmute()`: delete the original columns and only keep the new ones\ndplyr::transmute(sim.dat, total_exp = store_exp + online_exp) \n\n## Merge\n\n(x<-data.frame(cbind(ID=c(\"A\",\"B\",\"C\"),x1=c(1,2,3))))\n(y<-data.frame(cbind(ID=c(\"B\",\"C\",\"D\"),y1=c(T,T,F))))\n\n# join to the left\n# keep all rows in x\nleft_join(x,y,by=\"ID\")\n# get rows matched in both data sets\ninner_join(x,y,by=\"ID\")\n# get rows in either data set\nfull_join(x,y,by=\"ID\")\n# filter out rows in x that can be matched in y \n# it doesn't bring in any values from y \nsemi_join(x,y,by=\"ID\")\n# the opposite of  semi_join()\n# it gets rows in x that cannot be matched in y\n# it doesn't bring in any values from y\nanti_join(x,y,by=\"ID\")\n\n## Tidy and Reshape Data \n# Take a baby subset of our exemplary clothes consumers data to illustrate:\n(sdat<-sim.dat[1:5,1:6])\n\n# `reshape2` example\n(mdat <- melt(sdat, measure.vars=c(\"store_exp\",\"online_exp\"),\n              variable.name = \"Channel\",\n              value.name = \"Expense\"))\n\n# compare the online and in store expense between male and female based on the house ownership\ndcast(mdat, house + gender ~ Channel, sum)\n\n## `tidyr` package\n\n# practice functions we learnt before\nsdat<-sim.dat[1:5,]%>%\n  dplyr::select(age,gender,store_exp,store_trans)\nsdat %>% tbl_df()\n\n# `gather()`: Analogous to `melt()` in `reshape2`\nmsdat<-tidyr::gather(sdat,\"variable\",\"value\",store_exp,store_trans)\nmsdat %>% tbl_df()\n\n# pipe version\nsdat%>%gather(\"variable\",\"value\",store_exp,store_trans)\n\n# melt version\nmelt(sdat, measure.vars=c(\"store_exp\",\"store_trans\"),\n     variable.name = \"variable\",\n     value.name = \"value\")\n\n# spread\nmsdat %>% spread(variable,value)\n\n##  `separate()` and `unite()`\n\n# You can use `sep=` \n# By default, it is \"`_`\"\nsepdat<- msdat %>% \n  separate(variable,c(\"Source\",\"Type\"))\nsepdat %>% tbl_df()\n\nsepdat %>% \n  unite(\"variable\",Source,Type,sep=\"_\")\n\nsepdat %>% \n  unite(\"variable\",Source,Type,sep=\"_\")\n\n",
    "created" : 1501360036201.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1641139272",
    "id" : "F14EC9C6",
    "lastKnownWriteTime" : 1501026284,
    "last_content_update" : 1501026284,
    "path" : "~/Documents/GitHub/CE_JSM2017/Rcode/02-DataWrangling.R",
    "project_path" : "Rcode/02-DataWrangling.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}